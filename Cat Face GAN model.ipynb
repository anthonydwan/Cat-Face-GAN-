{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cat Face GAN model  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a project to test some of the concepts I have learnt for a Generative Adversial Network (GAN) and also to practise using Git. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Dataset Inspection \n",
    "\n",
    "Since the dataset I've obtained from https://github.com/Ferlix/Cat-faces-dataset should already be standardised to 29,842 64x64 RRB images of cats' faces, there shouldn't be a need to normalise them any further. However, it is still good practice to just take a look at the the pics just to make sure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from matplotlib.image import imread\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\data_science\\kaggle\\CatFaceGAN\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'D:\\\\data_science\\\\kaggle\\\\CatFaceGAN'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%cd \"D:/data_science/kaggle/CatFaceGAN\"\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgpath=r'dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension1 = []\n",
    "dimension2 = []\n",
    "colours = []\n",
    "for filename in os.listdir(imgpath):\n",
    "    img = imread(imgpath + '\\\\' + filename)\n",
    "    d1,d2,colour = img.shape\n",
    "    dimension1.append(d1)\n",
    "    dimension2.append(d2)\n",
    "    colours.append(colour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "3\n",
      "3\n",
      "29843\n"
     ]
    }
   ],
   "source": [
    "print (np.min(dimension1))\n",
    "print (np.max(dimension1))\n",
    "print (np.min(dimension2))\n",
    "print (np.max(dimension2))\n",
    "print (np.min(colours))\n",
    "print (np.max(colours))\n",
    "print(len(dimension1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above, it is safe to assume that all 29,843 images are 64x64 and are RGB mode. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: creating GAN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Reshape, Flatten, Conv2D, Conv2DTranspose\n",
    "from tensorflow.keras.layers import MaxPooling2D, BatchNormalization, Dropout, LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "coding_size = 100 \n",
    "#coding size will be the start of the generator shape \n",
    "#it should be smaller than the size of the final image (64x64) but not too small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generator is a model that takes in noise and creates images \n",
    "#these images will try to bypass the classifier (discriminator) and get fake images \n",
    "generator = Sequential() \n",
    "generator.add(Dense(8*8*128, input_shape=[coding_size]))\n",
    "generator.add(Reshape([8, 8, 128]))\n",
    "generator.add(BatchNormalization())\n",
    "generator.add(Conv2DTranspose(64, kernel_size=5, strides=2, \n",
    "                              padding=\"same\", activation=\"relu\"))\n",
    "generator.add(BatchNormalization())\n",
    "generator.add(Conv2DTranspose(64, kernel_size=5, strides=2, \n",
    "                              padding=\"same\", activation=\"relu\"))\n",
    "generator.add(BatchNormalization())\n",
    "generator.add(Conv2DTranspose(3, kernel_size=5, strides=2, \n",
    "                              padding=\"same\", activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 8192)              827392    \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, 16, 16, 64)        204864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 32, 32, 64)        102464    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 64, 64, 3)         4803      \n",
      "=================================================================\n",
      "Total params: 1,140,547\n",
      "Trainable params: 1,140,035\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#discriminator is a classification model, employing typical CNN techniques \n",
    "discriminator = Sequential() \n",
    "discriminator.add(Conv2D(64, kernel_size=5, strides=1, padding=\"same\",\n",
    "                        activation=LeakyReLU(0.3),\n",
    "                        input_shape=[64, 64, 3]))\n",
    "discriminator.add(MaxPooling2D(2,2))\n",
    "discriminator.add(Dropout(0.5))\n",
    "discriminator.add(Conv2D(64, kernel_size=5, strides=1, padding=\"same\",\n",
    "                        activation=LeakyReLU(0.3)))\n",
    "discriminator.add(MaxPooling2D(2,2))\n",
    "discriminator.add(Dropout(0.5))\n",
    "discriminator.add(Conv2D(64, kernel_size=5, strides=2, padding=\"same\",\n",
    "                        activation=LeakyReLU(0.3)))\n",
    "discriminator.add(Dropout(0.5))\n",
    "discriminator.add(Flatten())\n",
    "discriminator.add(Dense(64, activation='relu'))\n",
    "discriminator.add(Dense(64, activation='relu'))\n",
    "discriminator.add(Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 64, 64, 64)        4864      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 64)        102464    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 8, 64)          102464    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                262208    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 476,225\n",
      "Trainable params: 476,225\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAN=Sequential([generator,discriminator])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")\n",
    "discriminator.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAN.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: loading the images into train data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = []\n",
    "\n",
    "for filename in os.listdir(imgpath):\n",
    "    img = imread(imgpath + '\\\\' + filename)\n",
    "    training_data.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(training_data).reshape(-1,64,64,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29843, 64, 64, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_train = X_train/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_train.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.003921569"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_train.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: training GAN model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently on Epoch 1\n",
      "\t Currently on batch number 100 of 932\n",
      "\t Currently on batch number 200 of 932\n",
      "\t Currently on batch number 300 of 932\n",
      "\t Currently on batch number 400 of 932\n",
      "\t Currently on batch number 500 of 932\n",
      "\t Currently on batch number 600 of 932\n",
      "\t Currently on batch number 700 of 932\n",
      "\t Currently on batch number 800 of 932\n",
      "\t Currently on batch number 900 of 932\n",
      "Currently on Epoch 2\n",
      "\t Currently on batch number 100 of 932\n",
      "\t Currently on batch number 200 of 932\n",
      "\t Currently on batch number 300 of 932\n",
      "\t Currently on batch number 400 of 932\n",
      "\t Currently on batch number 500 of 932\n",
      "\t Currently on batch number 600 of 932\n",
      "\t Currently on batch number 700 of 932\n",
      "\t Currently on batch number 800 of 932\n",
      "\t Currently on batch number 900 of 932\n",
      "Currently on Epoch 3\n",
      "\t Currently on batch number 100 of 932\n",
      "\t Currently on batch number 200 of 932\n",
      "\t Currently on batch number 300 of 932\n",
      "\t Currently on batch number 400 of 932\n",
      "\t Currently on batch number 500 of 932\n",
      "\t Currently on batch number 600 of 932\n",
      "\t Currently on batch number 700 of 932\n",
      "\t Currently on batch number 800 of 932\n",
      "\t Currently on batch number 900 of 932\n",
      "Currently on Epoch 4\n",
      "\t Currently on batch number 100 of 932\n",
      "\t Currently on batch number 200 of 932\n",
      "\t Currently on batch number 300 of 932\n",
      "\t Currently on batch number 400 of 932\n",
      "\t Currently on batch number 500 of 932\n",
      "\t Currently on batch number 600 of 932\n",
      "\t Currently on batch number 700 of 932\n",
      "\t Currently on batch number 800 of 932\n",
      "\t Currently on batch number 900 of 932\n",
      "Currently on Epoch 5\n",
      "\t Currently on batch number 100 of 932\n",
      "\t Currently on batch number 200 of 932\n",
      "\t Currently on batch number 300 of 932\n",
      "\t Currently on batch number 400 of 932\n",
      "\t Currently on batch number 500 of 932\n",
      "\t Currently on batch number 600 of 932\n",
      "\t Currently on batch number 700 of 932\n",
      "\t Currently on batch number 800 of 932\n",
      "\t Currently on batch number 900 of 932\n",
      "Currently on Epoch 6\n",
      "\t Currently on batch number 100 of 932\n",
      "\t Currently on batch number 200 of 932\n",
      "\t Currently on batch number 300 of 932\n",
      "\t Currently on batch number 400 of 932\n",
      "\t Currently on batch number 500 of 932\n",
      "\t Currently on batch number 600 of 932\n",
      "\t Currently on batch number 700 of 932\n",
      "\t Currently on batch number 800 of 932\n",
      "\t Currently on batch number 900 of 932\n",
      "Currently on Epoch 7\n",
      "\t Currently on batch number 100 of 932\n",
      "\t Currently on batch number 200 of 932\n",
      "\t Currently on batch number 300 of 932\n",
      "\t Currently on batch number 400 of 932\n",
      "\t Currently on batch number 500 of 932\n",
      "\t Currently on batch number 600 of 932\n",
      "\t Currently on batch number 700 of 932\n",
      "\t Currently on batch number 800 of 932\n",
      "\t Currently on batch number 900 of 932\n",
      "Currently on Epoch 8\n",
      "\t Currently on batch number 100 of 932\n",
      "\t Currently on batch number 200 of 932\n",
      "\t Currently on batch number 300 of 932\n",
      "\t Currently on batch number 400 of 932\n",
      "\t Currently on batch number 500 of 932\n",
      "\t Currently on batch number 600 of 932\n",
      "\t Currently on batch number 700 of 932\n",
      "\t Currently on batch number 800 of 932\n",
      "\t Currently on batch number 900 of 932\n",
      "Currently on Epoch 9\n",
      "\t Currently on batch number 100 of 932\n",
      "\t Currently on batch number 200 of 932\n",
      "\t Currently on batch number 300 of 932\n",
      "\t Currently on batch number 400 of 932\n",
      "\t Currently on batch number 500 of 932\n",
      "\t Currently on batch number 600 of 932\n",
      "\t Currently on batch number 700 of 932\n",
      "\t Currently on batch number 800 of 932\n",
      "\t Currently on batch number 900 of 932\n",
      "Currently on Epoch 10\n",
      "\t Currently on batch number 100 of 932\n",
      "\t Currently on batch number 200 of 932\n",
      "\t Currently on batch number 300 of 932\n",
      "\t Currently on batch number 400 of 932\n",
      "\t Currently on batch number 500 of 932\n",
      "\t Currently on batch number 600 of 932\n",
      "\t Currently on batch number 700 of 932\n",
      "\t Currently on batch number 800 of 932\n",
      "\t Currently on batch number 900 of 932\n",
      "Currently on Epoch 11\n",
      "\t Currently on batch number 100 of 932\n",
      "\t Currently on batch number 200 of 932\n",
      "\t Currently on batch number 300 of 932\n",
      "\t Currently on batch number 400 of 932\n",
      "\t Currently on batch number 500 of 932\n",
      "\t Currently on batch number 600 of 932\n",
      "\t Currently on batch number 700 of 932\n",
      "\t Currently on batch number 800 of 932\n",
      "\t Currently on batch number 900 of 932\n",
      "Currently on Epoch 12\n",
      "\t Currently on batch number 100 of 932\n",
      "\t Currently on batch number 200 of 932\n",
      "\t Currently on batch number 300 of 932\n",
      "\t Currently on batch number 400 of 932\n",
      "\t Currently on batch number 500 of 932\n",
      "\t Currently on batch number 600 of 932\n",
      "\t Currently on batch number 700 of 932\n",
      "\t Currently on batch number 800 of 932\n",
      "\t Currently on batch number 900 of 932\n",
      "Currently on Epoch 13\n",
      "\t Currently on batch number 100 of 932\n",
      "\t Currently on batch number 200 of 932\n",
      "\t Currently on batch number 300 of 932\n",
      "\t Currently on batch number 400 of 932\n",
      "\t Currently on batch number 500 of 932\n",
      "\t Currently on batch number 600 of 932\n",
      "\t Currently on batch number 700 of 932\n",
      "\t Currently on batch number 800 of 932\n",
      "\t Currently on batch number 900 of 932\n",
      "Currently on Epoch 14\n",
      "\t Currently on batch number 100 of 932\n",
      "\t Currently on batch number 200 of 932\n",
      "\t Currently on batch number 300 of 932\n",
      "\t Currently on batch number 400 of 932\n",
      "\t Currently on batch number 500 of 932\n",
      "\t Currently on batch number 600 of 932\n",
      "\t Currently on batch number 700 of 932\n",
      "\t Currently on batch number 800 of 932\n",
      "\t Currently on batch number 900 of 932\n",
      "Currently on Epoch 15\n",
      "\t Currently on batch number 100 of 932\n",
      "\t Currently on batch number 200 of 932\n",
      "\t Currently on batch number 300 of 932\n",
      "\t Currently on batch number 400 of 932\n",
      "\t Currently on batch number 500 of 932\n",
      "\t Currently on batch number 600 of 932\n",
      "\t Currently on batch number 700 of 932\n",
      "\t Currently on batch number 800 of 932\n",
      "\t Currently on batch number 900 of 932\n",
      "Currently on Epoch 16\n",
      "\t Currently on batch number 100 of 932\n",
      "\t Currently on batch number 200 of 932\n",
      "\t Currently on batch number 300 of 932\n",
      "\t Currently on batch number 400 of 932\n",
      "\t Currently on batch number 500 of 932\n",
      "\t Currently on batch number 600 of 932\n",
      "\t Currently on batch number 700 of 932\n",
      "\t Currently on batch number 800 of 932\n",
      "\t Currently on batch number 900 of 932\n",
      "Currently on Epoch 17\n",
      "\t Currently on batch number 100 of 932\n",
      "\t Currently on batch number 200 of 932\n",
      "\t Currently on batch number 300 of 932\n",
      "\t Currently on batch number 400 of 932\n",
      "\t Currently on batch number 500 of 932\n",
      "\t Currently on batch number 600 of 932\n",
      "\t Currently on batch number 700 of 932\n",
      "\t Currently on batch number 800 of 932\n",
      "\t Currently on batch number 900 of 932\n",
      "Currently on Epoch 18\n",
      "\t Currently on batch number 100 of 932\n",
      "\t Currently on batch number 200 of 932\n",
      "\t Currently on batch number 300 of 932\n",
      "\t Currently on batch number 400 of 932\n",
      "\t Currently on batch number 500 of 932\n",
      "\t Currently on batch number 600 of 932\n",
      "\t Currently on batch number 700 of 932\n",
      "\t Currently on batch number 800 of 932\n",
      "\t Currently on batch number 900 of 932\n",
      "Currently on Epoch 19\n",
      "\t Currently on batch number 100 of 932\n",
      "\t Currently on batch number 200 of 932\n",
      "\t Currently on batch number 300 of 932\n",
      "\t Currently on batch number 400 of 932\n",
      "\t Currently on batch number 500 of 932\n",
      "\t Currently on batch number 600 of 932\n",
      "\t Currently on batch number 700 of 932\n",
      "\t Currently on batch number 800 of 932\n",
      "\t Currently on batch number 900 of 932\n",
      "Currently on Epoch 20\n",
      "\t Currently on batch number 100 of 932\n",
      "\t Currently on batch number 200 of 932\n",
      "\t Currently on batch number 300 of 932\n",
      "\t Currently on batch number 400 of 932\n",
      "\t Currently on batch number 500 of 932\n",
      "\t Currently on batch number 600 of 932\n",
      "\t Currently on batch number 700 of 932\n",
      "\t Currently on batch number 800 of 932\n",
      "\t Currently on batch number 900 of 932\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "my_data = scaled_train\n",
    "\n",
    "dataset= tf.data.Dataset.from_tensor_slices(my_data)\n",
    "dataset = dataset.shuffle(buffer_size=1000).batch(batch_size,drop_remainder=True)\n",
    "epochs = 20\n",
    "\n",
    "generator, discriminator = GAN.layers\n",
    "for epoch in range(epochs):\n",
    "      print(f\"Currently on Epoch {epoch+1}\")\n",
    "      i = 0\n",
    "      for X_batch in dataset:\n",
    "          i = i+1\n",
    "          if i%100 ==0:\n",
    "            print(f\"\\t Currently on batch number {i} of {len(my_data)//batch_size}\")\n",
    "          # Discriminator \n",
    "          noise = tf.random.normal(shape=[batch_size,coding_size])\n",
    "          gen_images = generator(noise)\n",
    "          X_fake_vs_real = tf.concat([gen_images, tf.dtypes.cast(X_batch, tf.float32)], axis=0)\n",
    "          y1 = tf.constant([[0.]]*batch_size+ [[1.]]* batch_size) #0 for the fake images and 1 for real]]\n",
    "          discriminator.trainable = True\n",
    "          discriminator.train_on_batch(X_fake_vs_real, y1)\n",
    "\n",
    "          # Generator\n",
    "          noise = tf.random.normal(shape=[batch_size, coding_size])\n",
    "          y2 = tf.constant([[1.]]*batch_size)\n",
    "          discriminator.trainable = False \n",
    "          GAN.train_on_batch(noise,y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = tf.random.normal(shape=[10, coding_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([10, 100])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1eab2b54508>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAABDCAYAAAC1DE+pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAX40lEQVR4nO2daXRdV3XH//s9SU/S0yxZgyVZ8qB4HuMkjp2BBCckJBDC0DKHoStrtUBDgVWSsNrSli5WWUDpaoO7IKErUEImIANJTUJIYkISj3E8yo4H2dZg6Vnz9Ca90w/v+e29L5ItXCt+WPv3RUfv7nvuPufse+49++5zDjnnYBiGYWQuvgutgGEYhnFmrKM2DMPIcKyjNgzDyHCsozYMw8hwrKM2DMPIcKyjNgzDyHAm1VET0U1EdICIDhHR3VOtlGEYhsHQ2eKoicgP4CCAGwC0AtgK4CPOuX1Tr55hGIaRNQmZywEccs4dAQAiehjAbQAm7Kiz8oMuu7gMAEBj+pjzj3+OI88P+Xyii/GLP8W1oBMloKwE/57wZEj8QPIP6oGEyiPO6bE8nYUvxml/WMjlajknspfl9UW1XCIgdBplfccCmBi/eLD69EOWIvLC4nfPs1iWI16gD+Z2cR0m6kV9hrKVnNTRJ+ssx6NvLufhE/qOjen28Y2KNk6I32NKDLGgPAkT4otwOiFUD/QklFysiDNxnvyyC/jisWHOxOXoPAJdnI4HOZOxfF23wVxWarSPjcZ7XVVnQyI/T91mjYjr5nOatHqoKe1NpztGi/lA2HNhqW6ezqQ0ly/WM1DA+gX0De7rY4P3dw+n07GqoJJL5PLFfGG2BRfU11XlzxP3S7aWc4PiRhOmlcjzGL/oP2T9/cE9J0/z9k3if2mf3vb2D4t7Wradtw9M3dPxUC/GBoe9V0vqOt6PHmoBnBD/twK44kwnZBeXofGzXwIABHq08tES1kMaVNzT2dGygXR6NMRWGAjpUkbLOJOcSq75yJCueV8OG1Tpy/piozNYp7xO1rd3qacT62SjKWvm/HoWaJ3iosFiJaxf4REtN9DEPVzpbj42MM9jXOKhM1bKluG9SbKPcrlIdITeB0T+Sc7/1DrdEy74D765ot/h9OgPZ2rdG7ku8kKc38AcfS03j/MI5rEiQ8O6DQK7uI2zh/j3YIcuY8c6cVMHJh4NFh7i+hyu5TaY98iwkmu9vjCd9j6Yq9e1pdPtW7j8Y7NHldzc77GOXZdzfn2rdMVfMf9IOr37mQWcX64uR+IS1jH/99wpDtdruYqd/H9oFf8uH/oA8LUPPZZOf3P3zem021eo5GSn45YPqmO3z3sznX70N+vS6bx5/Uou/xf8ICj5yWvpdMcn1iq5wYVcNwXN3ItFVg8pueArXP6+FXxOyQwtN7apLJ2WD+aRRWElhz4+WP4G2/Bgo64z+YLpfbmUL1j5bXxe/6qIkivdwuUabBS6FniepIXJiu/4+/swEZPxUY/Xw//BHUJEdxLRNiLaFh8ZHucUwzAM41yYjI/6SgBfd869K/X/PQDgnPvmROfkVdW7eR9NvlFHr9JP5pJf8hCoeyk/A7IH9PNgdCE/CYN7+O0rslI/BBKt/CaWI/IoOK7L1buY07lN+i0g+POidHqwnp9dI7PiSk4+nmZs4cds9wp9LSfcE75yfsoWF44oucTGinR6YC4/ZbOHdF1kD4o3fvH2OlSn5aKlwm2Rw3I0NvHbgj+sj8kRQKCTyxj3DOvi5Vw3VS+x3NAHdHtHIzxo8zdz23vf8kdrWKniBm6fwbdKlFz2ALdPlnixzb66W8s9xm9YoTVcpoqt+t2kdyGns+bot7TwEL8R1T8hyjhTv2JFxCgxRxQ/sb5XyQ208xtswVGul6FLPP4d0V75xyce9BacEHYW5/TJ6zzuiCHWt6SZ8x68Xt9L7hi3T6nHsRn/QE863dvJ94s/qHWfXcXtcOhQ9YS6Z/dwuWIVbEuzntT2WH/vwXR636mqdHrgQJmSk6PzO295Lp1++OilSq4nJHTvZR0qt2j9EqLaR6q1zQyvYMNzwmdbtFWPEvsXcblyOzjD8rUnlVxXb9IuWu/dgPDhtnFdH5N5o94KoImIZhNRDoAPA3hqEucZhmEY54Gz+qidc3Ei+jyAXyPpBv+Rc27vlGtmGIZhAJjcx0Q4554F8OwU62IYhmGMw1l91OdCoKHe1Xz1LgBAlicULlbNzkl/N3+BrV7SpeRGonzsqpn8tfzXG1fr/IqEc0p4d2qaQkqub1h80t9WrI7FirgOVl/TnE5vfWWBkssN8QWiJSJUaIH2y8owtBXVHDnw6sG5Sq5oO0emSH+W9/OtT4SJFW7xhCYIBprYN1m5mTOJFOk2iIri+6/QftSxzaWcx/Ws+/GT2ifob2V/XKKBfXZZWdo/GhM+6gV3d6bT3dfN0tf9MPtAB7ez794barbm5t3p9Es72cFcvFe/c0Su4TYpfIYjB7xRKdJHP1qlL5Y1wseCrZwemKfl8tvH9yBm6eAQDMzh8wqOi28hNR7/fynbQtk2Llc86AlpFO7h/tX8LWTGb3UcHyU4/671fJL/pJZr2Mh5nFg/cYxoTr+IKPK41xMiy2jxxH2LjKQIzOdvEpHIxO+OWXu4HYsP6zZY8kW2i99s5w9SOd36e0J+h/ieMMT6FZ7QERuHP8lyxTt0XZTtZ9ljd7Ae5DGDwB6+V4NXif7osQolN1SbvFbLA99FuP3EOfuoDcMwjAuIddSGYRgZzqR81H8svggQbEkOOUZq9RDF3yNmeInHRKi/QMnFQjxs2DjCQ9x4sc6v6CAPbQav4LFmz6s6NEjOngu2e4ZkV51KJ/eLEKBZz+kYstByHgJdc8OudPqll5YpuUQ25//6EXafeIdGcgidJWZWyWE2AIyu41BFOTMv5hlaBut4uN/lOBQsV3uV1ISXutIedWz3YnZphF6oTacTc/UYt2QJh2F9as7mdHrDz25RcjnCwg58i+u24Uc6v8JCHv7uaRKTX7K1K+X4ELtm6jfy7+3rdF1UP8J5tK3nPAqqdAjeUBdXaNF+PfsywpdC33LWd8ar+rbJ62bjCu7nIe6Bz1cpufddzTFgv/pfnjPmdR9Uv8i2kBVmG+ls1AZEczm8zolQwtClui4WfONwOj1Y35ROz73piJLbk9eYThce1TYYv5rbJ3yYQ9ykmwYAcorYLVD2JLdB7wKdX2ELp0f7OQQzUaHv77qlHMrWWsxtdfJaLRftYlstmsn3gb9Oy/U1cB75e9nWR6p1aF3+W5wervO4pvK5H5hzP/c58VztZgl89Vg6PRTlc3o8YbVFR5M6+rX3RWFv1IZhGBmOddSGYRgZjnXUhmEYGc4UhefVuep7kuF5voh+FgR6+H85LVlOkwZ0mE+4mv1ggU7tH5T+1t7l7Iv0eaa2lpSIBYa26PCYMTHdunEtrz81M6inmu94ZGk6HREzm72r0+X0cbr0LdYjt1PHa7W9Q0xnFf4p7+I7VM9Tz31vycWLdJ2Fy/i83G4+Fp6h88vpE8cWap1qnuSK73w/KxV8LV/JyfaRC+xUbtJ+3u6bOP/AHs5jdKb2Pee1sX+vfB+3d/hOHT5YGWQf86FNjel0rNAzjT+L/w9Uc/2Fe7UvsrCS8ws3e6arizC0he/mqczNz1yide/ia/WLQzNWdCq5zj2VrF811+2nl72m5H7y9HXpdDzIeZfv1O196lKxIFkP11+2jhbF8DL+xiFXosxr0eF5ctp0pFZ/n6l7hvPvn8Pp3FO63uUCZzK0cmSm9hUHxWJOAyfF4lDeFSFHhb++km3Jv1+vxoelXGjfDs4vy7Mm06i4F2b+XtjZ57SddbazLVTN7FPHZOjwUCvfw/N/oPuLA19iHRtq+TvYiZ16gbOGlckw2G1/+VMMHjh5zqvngYhaAAwCGAMQd86tPvMZhmEYxvnij4n6uM45d+rsYoZhGMb5ZErC8wCkvd9yCAoAEbHCW9EhHob5I1pOrt8qZ+YlinUMS38Rh/EtX8jhMM0v6ylohWt4aBP2bmbQxG6RllfrOe2rV3IVbWJ1Ov/4q7gBeqbZ8VViA4SwnlVYyJMg0S/W2s32LNIfj/Hwb8Yhcc6teozrb+YQRznLbsyzGPtYJevk9+t6717M18rbxq4K75q8g4tZXxLD1dBl+lq1j3NYUut6EcqVpxuh7gWxlngFuyd8D5Uruf03cxlJVKfXdZa9lNczj+3mqZi+Io+ddXF+pcfUIfSv5YbtGuHhtHcGo4wzjReItal36fC8PDGztUDMSn3Qt0bLLeahdtYWjhHsuVGvvpi7V7ujTpO4Ug/Bax7mMi74Mi/T88aMWiVX/H0exrev0zbYdjvfd7cv3ppOP/uU1j08k+/VnBB3LwmdHQJPsGshv2b8Gb+AdgnmiNX9Rqs8a8VvEeGo3Xzs7+55UMl95bE70un3fev5dPr+H79bKziPyzH4SqU6JGcyF7Wz7ge+otuDxMzrY/016bRn8i6OHE3aSfQMszIn+zHRAXiOiLYT0Z2TPMcwDMM4D0z2jXqdc66diCoBPE9Ezc65TVIg1YHfCQD+spLx8jAMwzDOgT866oOIvg5gyDn37Ylk8mrqXeNnkhsHjK3Uw/PyInYzdBzgIYU3gsE/n8+rup/HuOG79Ey6vtd4eClneMU8Q9xP3fLbdPrptiXq2Kk3WY94iRiXePZlK9jPX8llJIVcpB8Alq46mk7v2jk7nc4N6QGMHNaFKzgPV6c/VVc8y8PkvvliEwHPB+IZO7luj90i3Bae78ixSq4ob5RG9APsIppfwVMa277TpOTarxZbYgn3lgt4XB+zeAbjyb1czw3L25VcZAMPDfs+xpEYFT/Uw8nwF1i/6NMz+PxSXcjIEnYTyCOXNWj/xt4Qz2B1vytVx4ZEtETgsHDHePaTqNrCDdk3j21k9J16FmS0lYfuTthM8T7tV5LD+tq1vDBWea5e6H9vJ+te+hC7N06u9Sy+v6yD846JiIVNekif08fXveQTB9SxfSG+z+LbuJ5yL9cbNgzv4sW7ojXCzl7WdtZ7M7dPya+5jfM7deV2Xsbn5QiPTv3tR5Vc+yONnPdqvm7Rbs9Gk6Jq8jvZVnsWejbXELd0/bpWdezY1rp0OlbB1/rgqu1K7vGtHHNBudyvSFsCgNj8pIut7Wv3IXLkHDcOIKIgERWeTgO4EcCes51nGIZhnB8m4/qoAvBLIjot/5BzbuOZTzEMwzDOF5PZ4eUIgOVvgy6GYRjGOEzJzMT8pho3/3ufAQA0FOsZP0cfZV/niPDFJTzrlBcuYF907HciRGutniU06wvsuOp4Dy9G39+ky5XIEwt8x7QbSG6mmniJfWzXfVzvePnk9pXpdNFe9p1VvveEkht6gMOeOq9kPSq2aU9TaJ3Y/LJUrJDXolcSHCtiOZ+YqeWydRkDlez3Ky9kf2Zomw4TCwqXm3fltpV38qqAWx7i53PODTqEflkF+5hff5JXDyy5Vm/cGerlsKl4lHWvfF77DkPvYj9v4CB/k4gv1n7egnyWC29huwiu0fpFXuTZp7E14jvJ7kIlJ/3rFZfrmYTtnfxRvOk+rqjRGh1mKTeW7VzNdpGlo+kwJGZw5hVxe+e8XKTkZKhm2WbOz7txQPFN7Hs+cYLrIqdQzyrM2sn29LGPvJBO/8/By5TcaD/7Tkt26PYZmSm+Qwgzrtqqv0m0vodttWCfuKk9ntfhRdyOLs4HG36uBUMrufyxAtFfNOqY2LoK7hdad7Pv3huamn+M302vff+OdPq19kYlF32d+wHvN4nSt/iH7k/wfZb1it6QRM5eLj3AesRzPTOKy5P/H3nwuxg9aRsHGIZh/EliHbVhGEaGMyWuj4JLqt2y/0zOAApt18PuaDUPIQuaeXiVe60euub/F48b+ubxcKX2thYld7CDQ4x8LTwkLTiudeq9lIcrJW/qUCEZvta/iodkNKxd+L7wuKMSlDTr36PF/H/hCR7yDHgWfh9ezMPf0jIxxH9az8aTswJ9YlQ7cIMO14oNiqHmGOswZ552R/j+mfM/foMOFYrWjr+npdw/EABWvJPDtwainMfh3zcouaxhPi8gwr9iN+rZc8Nt7JLwD3E9NV6mQ6Paf8OzReXC94ee1zNRy5o5HKrvo1y3oy3a9RFsk3sX6mHyvFXs0jrWzUPhcLd2fRQ1CzsR1TRzww4lF36a74VjzTw8L9ul7WKkSiyaVc3lKNup5bb904Z0etH3/yqdHq3VY3USroXCI2xM4TXarRR8kcMHF31yvzq2/0HevCN6k9jj8IAe7seFq6G4ma81/6PNSu7AQ7yhRt8ysY/joA5VHMsXbSJms+a0e/aFFGUcyxULWe3S/Vvn1Zxf9SauT294nj8qZkt6Niu57mren/GFzRzqWzFXhw4PbOPw0RXrufxvPqf3Yh1bkLyPW+/dgPDhcwzPMwzDMC4s1lEbhmFkONZRG4ZhZDhTs3HA7DpX/Q9fSF4gS/t3XFg6XPnaNy7bq+Q2PcuhcDLMKVyu9a1bxWFiPc9yWFxgfUjJRWLsR4xt01OF3XIO3/qzS9iv+OPX1yq5OY8Kf3MD+8gC/bqMw9VcRrlB6mi9joUjUReFLfzMHJjv2TA0xHLRKj5WVadDH2NPsE+sR6zal9eqfe1lV7HPuq5QhzvufYL9Z3HhivVuvClDtMIzxKqCRVr3vBL2w481s3/YeSL4/cIHHq7hPLJ7vT5Lbv+mn7KPfmiWnmoe6OU8Wm4V05DrPX794+yXLWjR7y0Rdksj0DP+74D2Yeb0cR4BXbUYnM1yfvG9I1al7UKG5IXLWC5Sru1MfjeIlvCxQI+us4RYIXHuVTyF/vCr+nuCf1Tkt8gTW9jB3yECp7iM3vDOPLGRwKmVnPaGuK25kn22W15i/7dvnvablz/O7dO9hPWTugLAyBxWpP5XfKx1vZbLaxcbVOxnpUbKdZ1F38ONNzKsv+P4TogwRuF6l20FAP5r2Wh8z4hVEFfo5fP8xUnd/19TyA3DMIwLi3XUhmEYGc6UuD6IKARgGIDtCJOkAlYXp7G6YKwuGKsLoME5N2O8A1PSUQMAEW2zvRWTWF0wVheM1QVjdXFmzPVhGIaR4VhHbRiGkeFMZUf9gynM+08NqwvG6oKxumCsLs7AlPmoDcMwjPODuT4MwzAynCnpqInoJiI6QESHiOjuqbhGpkJE9UT0IhHtJ6K9RHRX6vcyInqeiN5K/S09W14XA0TkJ6I3iOhXqf9nE9HmVD08QkQ5Z8vjYoGISojocSJqTtnHldPRLojob1L3xh4i+hkR5U5nu5gM572jJiI/gPsA3AxgEYCPENGi832dDCYO4MvOuYUA1gD4XKr8dwN4wTnXBOCF1P/TgbsAyDUz/xXAv6XqoRfAZy+IVheGfwew0Tm3AMnt7fZjmtkFEdUC+GsAq51zSwD4AXwY09suzspUvFFfDuCQc+6Icy4K4GEAt03BdTIS51yHc25HKj2I5M1Yi2QdPJgSexDA+y6Mhm8fRFQH4BYA96f+JwDXA3g8JTIt6gEAiKgIwDUAHgAA51zUOdeHaWgXSO7VmkdEWQDyAXRgmtrFZJmKjroWgNxEsDX127SDiBoBrASwGUCVc64DSHbmAConPvOi4XsA/hbA6RWDygH0OedOr4YznWxjDoAQgP9OuYLuJ6IgppldOOfaAHwbwHEkO+h+ANsxfe1iUkxFRz3e6k/TLrSEiAoA/BzAF51zAxdan7cbIroVQJdzbrv8eRzR6WIbWQBWAdjgnFuJ5BILF7WbYzxSPvjbAMwGMBNAEEk3qZfpYheTYio66lYA9eL/OgDtE8helBBRNpKd9E+dc79I/dxJRDWp4zUAui6Ufm8T6wC8l4hakHR/XY/kG3ZJasgLTC/baAXQ6pzbnPr/cSQ77ulmF+sBHHXOhZxzMQC/ALAW09cuJsVUdNRbATSlvuLmIPmh4KkpuE5GkvLDPgBgv3Puu+LQUwDuSKXvAPDk263b24lz7h7nXJ1zrhFJG/itc+5jAF4E8MGU2EVfD6dxzp0EcIKI5qd+eieAfZhmdoGky2MNEeWn7pXT9TAt7WKyTNXqee9G8u3JD+BHzrl/Oe8XyVCI6CoAvwOwG+ybvRdJP/WjAGYhaawfcs71jJvJRQYRvQPAV5xztxLRHCTfsMsAvAHg4865yJnOv1ggohVIfljNAXAEwKeRfFmaVnZBRP8I4M+RjJB6A8BfIOmTnpZ2MRlsZqJhGEaGYzMTDcMwMhzrqA3DMDIc66gNwzAyHOuoDcMwMhzrqA3DMDIc66gNwzAyHOuoDcMwMhzrqA3DMDKc/wPXFO1iuYOEUgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = generator(noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_image = images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]], shape=(64, 64, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]], shape=(64, 64, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]], shape=(64, 64, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]], shape=(64, 64, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]], shape=(64, 64, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]], shape=(64, 64, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]], shape=(64, 64, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]], shape=(64, 64, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]], shape=(64, 64, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]], shape=(64, 64, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for image in images:\n",
    "    print(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cat Face GAN model  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a project to test some of the concepts I have learnt for a Generative Adversial Network (GAN) and also to practise using Git. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Dataset Inspection \n",
    "\n",
    "Since the dataset I've obtained from https://github.com/Ferlix/Cat-faces-dataset should already be standardised to 29,842 64x64 RRB images of cats' faces, there shouldn't be a need to normalise them any further. However, it is still good practice to just take a look at the the pics just to make sure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from matplotlib.image import imread\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\data_science\\kaggle\\CatFaceGAN\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'D:\\\\data_science\\\\kaggle\\\\CatFaceGAN'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%cd \"D:/data_science/kaggle/CatFaceGAN\"\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgpath=r'dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension1 = []\n",
    "dimension2 = []\n",
    "colours = []\n",
    "for filename in os.listdir(imgpath):\n",
    "    img = imread(imgpath + '\\\\' + filename)\n",
    "    d1,d2,colour = img.shape\n",
    "    dimension1.append(d1)\n",
    "    dimension2.append(d2)\n",
    "    colours.append(colour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "3\n",
      "3\n",
      "29843\n"
     ]
    }
   ],
   "source": [
    "print (np.min(dimension1))\n",
    "print (np.max(dimension1))\n",
    "print (np.min(dimension2))\n",
    "print (np.max(dimension2))\n",
    "print (np.min(colours))\n",
    "print (np.max(colours))\n",
    "print(len(dimension1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above, it is safe to assume that all 29,843 images are 64x64 and are RGB mode. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: creating GAN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Reshape, Flatten, Conv2D, Conv2DTranspose\n",
    "from tensorflow.keras.layers import MaxPooling2D, BatchNormalization, Dropout, LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "coding_size = 100 \n",
    "#coding size will be the start of the generator shape \n",
    "#it should be smaller than the size of the final image (64x64) but not too small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generator is a model that takes in noise and creates images \n",
    "#these images will try to bypass the classifier (discriminator) and get fake images \n",
    "generator = Sequential() \n",
    "generator.add(Dense(8*8*128, input_shape=[coding_size]))\n",
    "generator.add(Reshape([8, 8, 128]))\n",
    "generator.add(BatchNormalization())\n",
    "generator.add(Conv2DTranspose(64, kernel_size=5, strides=2, padding=\"same\",\n",
    "                                 activation=\"relu\"))\n",
    "generator.add(BatchNormalization())\n",
    "generator.add(Conv2DTranspose(64, kernel_size=5, strides=2, padding=\"same\",\n",
    "                                 activation=\"relu\"))\n",
    "generator.add(BatchNormalization())\n",
    "generator.add(Conv2DTranspose(3, kernel_size=5, strides=2, padding=\"same\",\n",
    "                                 activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 8192)              827392    \n",
      "_________________________________________________________________\n",
      "reshape_5 (Reshape)          (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_13 (Conv2DT (None, 16, 16, 64)        204864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_14 (Conv2DT (None, 32, 32, 64)        102464    \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_15 (Conv2DT (None, 64, 64, 3)         4803      \n",
      "=================================================================\n",
      "Total params: 1,140,547\n",
      "Trainable params: 1,140,035\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#discriminator is a classification model, employing typical CNN techniques \n",
    "discriminator = Sequential() \n",
    "discriminator.add(Conv2D(64, kernel_size=5, strides=1, padding=\"same\",\n",
    "                        activation=LeakyReLU(0.3),\n",
    "                        input_shape=[64, 64, 3]))\n",
    "discriminator.add(MaxPooling2D(2,2))\n",
    "discriminator.add(Dropout(0.5))\n",
    "discriminator.add(Conv2D(64, kernel_size=5, strides=1, padding=\"same\",\n",
    "                        activation=LeakyReLU(0.3)))\n",
    "discriminator.add(MaxPooling2D(2,2))\n",
    "discriminator.add(Dropout(0.5))\n",
    "discriminator.add(Conv2D(64, kernel_size=5, strides=2, padding=\"same\",\n",
    "                        activation=LeakyReLU(0.3)))\n",
    "discriminator.add(Dropout(0.5))\n",
    "discriminator.add(Flatten())\n",
    "discriminator.add(Dense(64, activation='relu'))\n",
    "discriminator.add(Dense(64, activation='relu'))\n",
    "discriminator.add(Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 64, 64, 64)        4864      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 32, 32, 64)        102464    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 8, 8, 64)          102464    \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 64)                262208    \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 476,225\n",
      "Trainable params: 476,225\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAN=Sequential([generator,discriminator])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")\n",
    "discriminator.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAN.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: loading the images into train data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29843 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(horizontal_flip=True, rescale=1/255)\n",
    "train_datagen = datagen.flow_from_directory(directory='D:/data_science/kaggle/CatFaceGAN', target_size=(64,64),color_mode='rgb',\n",
    "                                            batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: training GAN model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
